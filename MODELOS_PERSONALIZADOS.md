# üîß Gu√≠a para Probar Modelos Personalizados

Esta gu√≠a te explica **paso a paso** c√≥mo agregar y probar tus propios modelos en el sistema de Credit Risk Analysis.

---

## üéØ Resumen R√°pido

Para agregar un modelo nuevo, solo necesitas:

1. **Abrir** `src/models_config.py`
2. **Agregar** tu modelo al diccionario (3 campos: `class`, `params`, `class_weight`)
3. **Ejecutar** `python -m src.train_model`
4. **Listo** - Tu modelo se entrenar√° y comparar√° autom√°ticamente con los dem√°s

---

## üìã Prerequisitos

Antes de empezar, aseg√∫rate de tener:

- ‚úÖ Python instalado
- ‚úÖ El proyecto configurado (dependencias instaladas)
- ‚úÖ El dataset en `data/raw/PAKDD2010_Modeling_Data.txt`
- ‚úÖ Conocimiento b√°sico de scikit-learn (opcional, pero √∫til)

**No necesitas** modificar c√≥digo complejo, solo editar un archivo de configuraci√≥n.

---

## üìù Paso a Paso: Agregar un Nuevo Modelo

### Paso 1: Abrir el archivo de configuraci√≥n

Abre `src/models_config.py` en tu editor. Ver√°s algo as√≠:

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

def get_models_config() -> Dict[str, Dict[str, Any]]:
    return {
        "Logistic Regression": { ... },
        "Random Forest": { ... },
        "Gradient Boosting": { ... },
    }
```

### Paso 2: Importar tu modelo (si es necesario)

Si tu modelo no est√° en los imports, agr√©galo arriba. Por ejemplo, para XGBoost:

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier  # <-- Agregar aqu√≠
```

**Nota**: Si usas un modelo de scikit-learn que ya est√° importado, puedes saltarte este paso.

### Paso 3: Agregar tu modelo al diccionario

Dentro de `get_models_config()`, agrega una nueva entrada. **Ejemplo con XGBoost**:

```python
def get_models_config() -> Dict[str, Dict[str, Any]]:
    return {
        "Logistic Regression": { ... },
        "Random Forest": { ... },
        "Gradient Boosting": { ... },

        # Tu nuevo modelo aqu√≠:
        "XGBoost": {
            "class": XGBClassifier,
            "params": {
                "n_estimators": 200,
                "max_depth": 6,
                "learning_rate": 0.1,
                "random_state": 42,
            },
            "class_weight": "sample_weight",
        },
    }
```

### Paso 4: Ejecutar el entrenamiento

Guarda el archivo y ejecuta:

```bash
python -m src.train_model
```

**¬°Eso es todo!** Tu modelo se entrenar√° autom√°ticamente y se comparar√° con los dem√°s. Ver√°s los resultados en la consola y en `models/training_history/`.

---

## üîç Explicaci√≥n de los 3 Campos Necesarios

Cada modelo necesita **exactamente 3 campos**:

### 1. `"class"` - La clase del modelo

Es la clase del modelo de scikit-learn (sin par√©ntesis). Ejemplos:

```python
"class": LogisticRegression
"class": RandomForestClassifier
"class": XGBClassifier  # Si usas XGBoost
```

**‚ö†Ô∏è Importante**: El modelo DEBE tener `predict_proba()`. Algunos modelos necesitan configuraci√≥n especial:

- **SVC**: Agrega `"probability": True` en `params`
- La mayor√≠a de modelos de scikit-learn ya lo tienen

### 2. `"params"` - Los hiperpar√°metros

Diccionario con los par√°metros del modelo. Ejemplos:

```python
"params": {
    "random_state": 42,      # Siempre incluir para reproducibilidad
    "n_estimators": 200,     # Par√°metros espec√≠ficos del modelo
    "max_depth": 6,
    "learning_rate": 0.1,
}
```

**üí° Tip**: Puedes usar los valores por defecto de scikit-learn o ajustarlos seg√∫n tu experiencia. Siempre incluye `"random_state": 42` si el modelo lo soporta.

### 3. `"class_weight"` - Estrategia de balanceo

C√≥mo manejar el desbalanceo de clases (tenemos ~74% clase 0, ~26% clase 1). **3 opciones**:

#### Opci√≥n A: `"balanced"` (recomendado si el modelo lo soporta)

```python
"class_weight": "balanced"
```

**Usa esto para**: LogisticRegression, RandomForest, SVC, etc.

#### Opci√≥n B: `"sample_weight"` (para modelos sin class_weight)

```python
"class_weight": "sample_weight"
```

**Usa esto para**: GradientBoosting, XGBoost, LightGBM, etc.

#### Opci√≥n C: `None` (no recomendado)

```python
"class_weight": None
```

**No recomendado** porque el dataset est√° desbalanceado.

**¬øC√≥mo saber cu√°l usar?**

- Si el modelo tiene el par√°metro `class_weight` ‚Üí usa `"balanced"`
- Si NO tiene `class_weight` ‚Üí usa `"sample_weight"`
- Consulta la documentaci√≥n de scikit-learn si tienes dudas

---

## üìä Ejemplo Completo: Agregar XGBoost

Vamos a agregar XGBoost paso a paso:

### Paso 1: Instalar XGBoost

```bash
pip install xgboost
```

### Paso 2: Modificar `src/models_config.py`

**Antes:**

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

def get_models_config() -> Dict[str, Dict[str, Any]]:
    return {
        "Logistic Regression": { ... },
        "Random Forest": { ... },
        "Gradient Boosting": { ... },
    }
```

**Despu√©s:**

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier  # <-- Agregar import

def get_models_config() -> Dict[str, Dict[str, Any]]:
    return {
        "Logistic Regression": { ... },
        "Random Forest": { ... },
        "Gradient Boosting": { ... },

        "XGBoost": {  # <-- Agregar modelo nuevo
            "class": XGBClassifier,
            "params": {
                "n_estimators": 200,
                "max_depth": 6,
                "learning_rate": 0.1,
                "random_state": 42,
            },
            "class_weight": "sample_weight",  # XGBoost no tiene class_weight
        },
    }
```

### Paso 3: Ejecutar

```bash
python -m src.train_model
```

**Resultado**: XGBoost se entrenar√° junto con los otros modelos y ver√°s sus m√©tricas en la consola.

---

## üìà M√©tricas que se Calculan Autom√°ticamente

Para cada modelo, el sistema calcula y guarda:

### M√©tricas en Train (threshold=0.5)

- ROC-AUC
- F1-Score
- Precision
- Recall

### M√©tricas en Validation (threshold=0.5)

- ROC-AUC
- F1-Score
- Precision
- Recall

### M√©tricas en Validation (threshold √≥ptimo)

- F1-Score
- Precision
- Recall
- **Threshold √≥ptimo** (calculado con Youden's J statistic)

### Informaci√≥n Adicional

- ‚è±Ô∏è Tiempo de entrenamiento
- ‚öôÔ∏è Hiperpar√°metros usados
- ‚öñÔ∏è Estrategia de balanceo

**Nota**: El conjunto de test se guarda en memoria pero NO se usa para evaluaci√≥n (se reserva para evaluaci√≥n final del modelo seleccionado).

---

## üìÅ Archivos que se Generan

Despu√©s de ejecutar `python -m src.train_model`, se crean:

1. **`models/production/model.joblib`**

   - El mejor modelo (seleccionado por ROC-AUC en validation)
   - Se usa autom√°ticamente por la API

2. **`models/production/preprocessor.joblib`**

   - Pipeline de preprocessing guardado
   - Se usa autom√°ticamente por la API

3. **`models/production/metrics.txt`**

   - M√©tricas del mejor modelo en formato legible
   - F√°cil de leer y compartir

4. **`models/production/optimal_threshold.txt`**

   - Threshold √≥ptimo del mejor modelo
   - Se usa autom√°ticamente por la API para decisiones

5. **`models/training_history/training_history_YYYYMMDD_HHMMSS.json`**
   - Historial completo de TODOS los modelos entrenados
   - Incluye m√©tricas, hiperpar√°metros, tiempos, etc.
   - √ötil para comparar modelos

---

## üéØ Selecci√≥n del Mejor Modelo

El sistema selecciona el mejor modelo bas√°ndose en:

- **ROC-AUC en el conjunto de Validation**

Si quieres cambiar este criterio, modifica la funci√≥n `train_models()` en `src/train_model.py`, espec√≠ficamente esta l√≠nea:

```python
if val_roc_auc > best_score:
    best_score = val_roc_auc
    best_model = model
    best_model_name = model_name
```

Puedes cambiarlo a otra m√©trica (F1, Precision, Recall, etc.).

---

## ‚ö†Ô∏è Consideraciones Importantes

### 1. M√©todo `predict_proba()`

**IMPORTANTE**: Tu modelo DEBE tener el m√©todo `predict_proba()`. Algunos modelos requieren configuraci√≥n especial:

- **SVC**: Agrega `"probability": True` en params
- **Otros modelos**: Consulta la documentaci√≥n de scikit-learn

### 2. Balanceo de Clases

Este dataset est√° desbalanceado (muchos m√°s casos clase 0 que clase 1). Por eso es importante usar balanceo:

- Usa `"class_weight": "balanced"` si el modelo lo soporta
- Usa `"sample_weight": "sample_weight"` si el modelo NO tiene `class_weight`

### 3. Reproducibilidad

Siempre incluye `"random_state": 42` en los params si tu modelo lo soporta para tener resultados reproducibles.

### 4. Hiperpar√°metros

Ajusta los hiperpar√°metros seg√∫n tu conocimiento del modelo. Puedes usar:

- Valores por defecto de scikit-learn
- Valores encontrados en la literatura
- Optimizaci√≥n de hiperpar√°metros (GridSearchCV, etc.)

---

## ‚úÖ Verificar que Todo Funciona

Despu√©s de agregar tu modelo:

1. **Ejecuta**: `python -m src.train_model`
2. **Revisa la consola**: Deber√≠as ver las m√©tricas de tu modelo impresas
3. **Revisa `models/training_history/`**: Abre el JSON m√°s reciente para ver todos los detalles
4. **Compara m√©tricas**: ¬øTu modelo es mejor que los dem√°s? Revisa el ROC-AUC en validation

**Si hay errores:**

- Verifica que el import est√© correcto
- Verifica que el modelo tenga `predict_proba()`
- Revisa que los hiperpar√°metros sean v√°lidos para ese modelo

---

## üìö Recursos √ötiles

- [Documentaci√≥n de scikit-learn](https://scikit-learn.org/stable/)
- [Gu√≠a de clasificaci√≥n desbalanceada](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting)
- [Tuning de hiperpar√°metros](https://scikit-learn.org/stable/modules/grid_search.html)

---

## ‚ùì Preguntas Frecuentes

### ¬øPuedo usar modelos de otras librer√≠as (TensorFlow, PyTorch)?

Actualmente el sistema est√° dise√±ado para modelos de **scikit-learn** que tienen la interfaz est√°ndar (`fit()`, `predict()`, `predict_proba()`).

Para otros frameworks necesitar√≠as crear un wrapper que implemente esta interfaz. Si necesitas ayuda con esto, consulta con el equipo.

### ¬øD√≥nde veo los resultados de todos los modelos?

Revisa los archivos JSON en `models/training_history/`. Cada archivo contiene:

- M√©tricas de todos los modelos
- Hiperpar√°metros usados
- Tiempos de entrenamiento
- Threshold √≥ptimo de cada modelo

**Ejemplo**: Abre `training_history_20251218_043613.json` y busca tu modelo por nombre.

### ¬øPuedo entrenar solo algunos modelos?

S√≠, simplemente **comenta o elimina** las entradas que no quieras en `get_models_config()`:

```python
return {
    "Logistic Regression": { ... },
    # "Random Forest": { ... },  # <-- Comentado, no se entrenar√°
    "Gradient Boosting": { ... },
}
```

### ¬øQu√© pasa si mi modelo da error?

1. Verifica que el import est√© correcto
2. Verifica que los hiperpar√°metros sean v√°lidos
3. Verifica que el modelo tenga `predict_proba()`
4. Revisa el mensaje de error en la consola

El sistema continuar√° entrenando los otros modelos aunque uno falle.

---

## üöÄ Resumen: Pasos R√°pidos

1. **Abrir** `src/models_config.py`
2. **Agregar import** (si es necesario)
3. **Agregar modelo** al diccionario con 3 campos:
   - `"class"`: La clase del modelo
   - `"params"`: Hiperpar√°metros
   - `"class_weight"`: `"balanced"` o `"sample_weight"`
4. **Ejecutar** `python -m src.train_model`
5. **Revisar resultados** en consola y `models/training_history/`

---

## üí° Tips Finales

- **Empieza simple**: Usa valores por defecto o valores comunes de la literatura
- **Experimenta**: Prueba diferentes hiperpar√°metros y compara resultados
- **Revisa el historial**: Los JSON tienen toda la informaci√≥n para comparar modelos
- **No te preocupes por errores**: El sistema continuar√° con otros modelos si uno falla

**¬°√âxito con tus experimentos!** üéâ
