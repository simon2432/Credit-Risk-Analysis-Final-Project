# üìä Preprocessing Implementado - Documentaci√≥n Completa

## üéØ Objetivo

Este documento describe **exactamente c√≥mo est√° implementado** el pipeline de preprocessing en el c√≥digo actual (`src/preprocessing.py`).

El pipeline procesa los datos en **6 pasos secuenciales**, transformando 53 columnas originales en ~117 features finales normalizadas.

---

## üìã Estructura del Dataset (54 columnas)

### Variables con Descripci√≥n Completa:

#### **Identificadores:**

- **`ID_CLIENT`** (Var_Id: 1)
  - **Descripci√≥n:** N√∫mero secuencial para el solicitante (usar como clave)
  - **Valores:** 1-50000 (train), 50001-70000 (test), 70001-90000 (prediction)
  - **Acci√≥n:** Remover antes del preprocessing

#### **Variables de Aplicaci√≥n:**

- **`CLERK_TYPE`** (Var_Id: 2)

  - **Descripci√≥n:** Tipo de empleado/clerk (no informado)
  - **Valores:** C
  - **Tipo:** Categ√≥rica

- **`PAYMENT_DAY`** (Var_Id: 3)

  - **Descripci√≥n:** D√≠a del mes elegido por el solicitante para el pago de la factura
  - **Valores:** 1, 5, 10, 15, 20, 25
  - **Tipo:** Num√©rica discreta

- **`APPLICATION_SUBMISSION_TYPE`** (Var_Id: 4)

  - **Descripci√≥n:** Indica si la aplicaci√≥n fue enviada v√≠a internet o en persona/por correo
  - **Valores:** Web, Carga
  - **Tipo:** Categ√≥rica binaria

- **`QUANT_ADDITIONAL_CARDS`** (Var_Id: 5)

  - **Descripci√≥n:** Cantidad de tarjetas adicionales solicitadas en el mismo formulario
  - **Valores:** 1, 2, NULL
  - **Tipo:** Num√©rica discreta

- **`POSTAL_ADDRESS_TYPE`** (Var_Id: 6)
  - **Descripci√≥n:** Indica si la direcci√≥n postal es la del hogar u otra. Encoding no informado
  - **Valores:** 1, 2
  - **Tipo:** Num√©rica/categ√≥rica

#### **Variables Demogr√°ficas:**

- **`SEX`** (Var_Id: 7)

  - **Descripci√≥n:** Sexo del solicitante
  - **Valores:** M=Male, F=Female
  - **Tipo:** Categ√≥rica binaria

- **`MARITAL_STATUS`** (Var_Id: 8)

  - **Descripci√≥n:** Estado civil. Encoding no informado
  - **Valores:** 1, 2, 3, 4, 5, 6, 7
  - **Tipo:** Num√©rica/categ√≥rica ordinal

- **`QUANT_DEPENDANTS`** (Var_Id: 9)

  - **Descripci√≥n:** Cantidad de dependientes
  - **Valores:** 0, 1, 2, ...
  - **Tipo:** Num√©rica discreta

- **`EDUCATION_LEVEL`** (Var_Id: 10)

  - **Descripci√≥n:** Nivel educativo en orden gradual. Encoding no informado
  - **Valores:** 1, 2, 3, 4, 5
  - **Tipo:** Num√©rica/categ√≥rica ordinal

- **`STATE_OF_BIRTH`** (Var_Id: 11)

  - **Descripci√≥n:** Estado de nacimiento
  - **Valores:** Estados brasile√±os, XX, missing
  - **Tipo:** Categ√≥rica

- **`CITY_OF_BIRTH`** (Var_Id: 12)

  - **Descripci√≥n:** Ciudad de nacimiento
  - **Valores:** Varios
  - **Tipo:** Categ√≥rica (alta cardinalidad)

- **`NACIONALITY`** (Var_Id: 13)
  - **Descripci√≥n:** Pa√≠s de nacimiento. Encoding no informado pero Brasil probablemente es 1
  - **Valores:** 0, 1, 2
  - **Tipo:** Num√©rica/categ√≥rica

#### **Variables de Residencia:**

- **`RESIDENCIAL_STATE`** (Var_Id: 14)

  - **Descripci√≥n:** Estado de residencia
  - **Valores:** Estados brasile√±os
  - **Tipo:** Categ√≥rica

- **`RESIDENCIAL_CITY`** (Var_Id: 15)

  - **Descripci√≥n:** Ciudad de residencia
  - **Valores:** Varios
  - **Tipo:** Categ√≥rica (alta cardinalidad)

- **`RESIDENCIAL_BOROUGH`** (Var_Id: 16)

  - **Descripci√≥n:** Barrio de residencia
  - **Valores:** Varios
  - **Tipo:** Categ√≥rica (alta cardinalidad)

- **`FLAG_RESIDENCIAL_PHONE`** (Var_Id: 17)

  - **Descripci√≥n:** Indica si el solicitante posee tel√©fono residencial
  - **Valores:** Y, N
  - **Tipo:** Categ√≥rica binaria

- **`RESIDENCIAL_PHONE_AREA_CODE`** (Var_Id: 18)

  - **Descripci√≥n:** C√≥digo de √°rea de tres d√≠gitos (pseudo-c√≥digo)
  - **Valores:** C√≥digos de √°rea
  - **Tipo:** Categ√≥rica

- **`RESIDENCE_TYPE`** (Var_Id: 19)

  - **Descripci√≥n:** Tipo de residencia. Encoding no informado. Generalmente: propia, hipoteca, alquilada, padres, familia, etc.
  - **Valores:** 1, 2, 3, 4, 5, NULL
  - **Tipo:** Num√©rica/categ√≥rica

- **`MONTHS_IN_RESIDENCE`** (Var_Id: 20)

  - **Descripci√≥n:** Tiempo en la residencia actual en meses
  - **Valores:** 1, 2, ..., NULL
  - **Tipo:** Num√©rica continua

- **`RESIDENCIAL_ZIP_3`** (Var_Id: 52)
  - **Descripci√≥n:** Tres d√≠gitos m√°s significativos del c√≥digo postal real del hogar
  - **Valores:** C√≥digos postales
  - **Tipo:** Num√©rica/categ√≥rica

#### **Variables Financieras:**

- **`PERSONAL_MONTHLY_INCOME`** (Var_Id: 23)

  - **Descripci√≥n:** Ingreso mensual regular personal del solicitante en moneda brasile√±a (R$)
  - **Valores:** Valores num√©ricos
  - **Tipo:** Num√©rica continua
  - **Nota:** Variable cr√≠tica, puede tener outliers

- **`OTHER_INCOMES`** (Var_Id: 24)

  - **Descripci√≥n:** Otros ingresos del solicitante promediados mensualmente en moneda brasile√±a (R$)
  - **Valores:** Valores num√©ricos
  - **Tipo:** Num√©rica continua

- **`PERSONAL_ASSETS_VALUE`** (Var_Id: 32)

  - **Descripci√≥n:** Valor total de posesiones personales como casas, autos, etc. en moneda brasile√±a (R$)
  - **Valores:** Valores num√©ricos
  - **Tipo:** Num√©rica continua
  - **Nota:** Puede tener outliers extremos

- **`QUANT_BANKING_ACCOUNTS`** (Var_Id: 30)

  - **Descripci√≥n:** Cantidad de cuentas bancarias
  - **Valores:** 0, 1, 2
  - **Tipo:** Num√©rica discreta

- **`QUANT_SPECIAL_BANKING_ACCOUNTS`** (Var_Id: 31)
  - **Descripci√≥n:** Cantidad de cuentas bancarias especiales
  - **Valores:** 0, 1, 2
  - **Tipo:** Num√©rica discreta

#### **Variables de Tarjetas:**

- **`FLAG_VISA`** (Var_Id: 25)

  - **Descripci√≥n:** Flag indicando si el solicitante es titular de tarjeta VISA
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria

- **`FLAG_MASTERCARD`** (Var_Id: 26)

  - **Descripci√≥n:** Flag indicando si el solicitante es titular de tarjeta MASTERCARD
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria

- **`FLAG_DINERS`** (Var_Id: 27)

  - **Descripci√≥n:** Flag indicando si el solicitante es titular de tarjeta DINERS
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria

- **`FLAG_AMERICAN_EXPRESS`** (Var_Id: 28)

  - **Descripci√≥n:** Flag indicando si el solicitante es titular de tarjeta AMERICAN EXPRESS
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria

- **`FLAG_OTHER_CARDS`** (Var_Id: 29)
  - **Descripci√≥n:** A pesar de ser "FLAG", este campo presenta tres valores no explicados
  - **Valores:** 0, 1, NULL
  - **Tipo:** Num√©rica/categ√≥rica

#### **Variables de Empleo:**

- **`COMPANY`** (Var_Id: 34)

  - **Descripci√≥n:** Si el solicitante ha proporcionado el nombre de la compa√±√≠a donde trabaja formalmente
  - **Valores:** Y, N
  - **Tipo:** Categ√≥rica binaria

- **`PROFESSIONAL_STATE`** (Var_Id: 35)

  - **Descripci√≥n:** Estado donde trabaja el solicitante
  - **Valores:** Estados brasile√±os
  - **Tipo:** Categ√≥rica

- **`PROFESSIONAL_CITY`** (Var_Id: 36)

  - **Descripci√≥n:** Ciudad donde trabaja el solicitante
  - **Valores:** Varios
  - **Tipo:** Categ√≥rica (alta cardinalidad, muchos missing)

- **`PROFESSIONAL_BOROUGH`** (Var_Id: 37)

  - **Descripci√≥n:** Barrio donde trabaja el solicitante
  - **Valores:** Varios
  - **Tipo:** Categ√≥rica (alta cardinalidad, muchos missing)

- **`FLAG_PROFESSIONAL_PHONE`** (Var_Id: 38)

  - **Descripci√≥n:** Indica si se proporcion√≥ el n√∫mero de tel√©fono profesional
  - **Valores:** Y, N
  - **Tipo:** Categ√≥rica binaria

- **`PROFESSIONAL_PHONE_AREA_CODE`** (Var_Id: 39)

  - **Descripci√≥n:** C√≥digo de √°rea de tres d√≠gitos (pseudo-c√≥digo)
  - **Valores:** C√≥digos de √°rea
  - **Tipo:** Categ√≥rica

- **`MONTHS_IN_THE_JOB`** (Var_Id: 40)

  - **Descripci√≥n:** Tiempo en el trabajo actual en meses
  - **Valores:** Valores num√©ricos
  - **Tipo:** Num√©rica continua

- **`PROFESSION_CODE`** (Var_Id: 41)

  - **Descripci√≥n:** C√≥digo de profesi√≥n del solicitante. Encoding no informado
  - **Valores:** 1, 2, 3, ...
  - **Tipo:** Num√©rica/categ√≥rica

- **`OCCUPATION_TYPE`** (Var_Id: 42)

  - **Descripci√≥n:** Tipo de ocupaci√≥n. Encoding no informado
  - **Valores:** 1, 2, 3, 4, 5, NULL
  - **Tipo:** Num√©rica/categ√≥rica

- **`MATE_PROFESSION_CODE`** (Var_Id: 43)

  - **Descripci√≥n:** C√≥digo de profesi√≥n del c√≥nyuge. Encoding no informado
  - **Valores:** 1, 2, 3, ..., NULL
  - **Tipo:** Num√©rica/categ√≥rica (muchos missing)

- **`PROFESSIONAL_ZIP_3`** (Var_Id: 53)
  - **Descripci√≥n:** Tres d√≠gitos m√°s significativos del c√≥digo postal real del trabajo
  - **Valores:** C√≥digos postales
  - **Tipo:** Num√©rica/categ√≥rica

#### **Variables de Contacto:**

- **`FLAG_MOBILE_PHONE`** (Var_Id: 21)

  - **Descripci√≥n:** Indica si el solicitante posee tel√©fono m√≥vil
  - **Valores:** Y, N
  - **Tipo:** Categ√≥rica binaria

- **`FLAG_EMAIL`** (Var_Id: 22)
  - **Descripci√≥n:** Indica si el solicitante posee direcci√≥n de email
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria

#### **Variables de Documentaci√≥n:**

- **`FLAG_HOME_ADDRESS_DOCUMENT`** (Var_Id: 45)

  - **Descripci√≥n:** Flag indicando confirmaci√≥n documental de direcci√≥n del hogar
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria

- **`FLAG_RG`** (Var_Id: 46)

  - **Descripci√≥n:** Flag indicando confirmaci√≥n documental del n√∫mero de c√©dula de ciudadan√≠a
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria

- **`FLAG_CPF`** (Var_Id: 47)

  - **Descripci√≥n:** Flag indicando confirmaci√≥n documental del estado de contribuyente
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria

- **`FLAG_INCOME_PROOF`** (Var_Id: 48)
  - **Descripci√≥n:** Flag indicando confirmaci√≥n documental de ingresos
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria

#### **Otras Variables:**

- **`QUANT_CARS`** (Var_Id: 33)

  - **Descripci√≥n:** Cantidad de autos que posee el solicitante
  - **Valores:** Valores num√©ricos
  - **Tipo:** Num√©rica discreta

- **`MATE_EDUCATION_LEVEL`** (Var_Id: 44)

  - **Descripci√≥n:** Nivel educativo del c√≥nyuge en orden gradual. Encoding no informado
  - **Valores:** 1, 2, 3, 4, 5, NULL
  - **Tipo:** Num√©rica/categ√≥rica ordinal (muchos missing)

- **`PRODUCT`** (Var_Id: 49)

  - **Descripci√≥n:** Tipo de producto de cr√©dito solicitado. Encoding no informado
  - **Valores:** 1, 2, 7
  - **Tipo:** Num√©rica/categ√≥rica

- **`FLAG_ACSP_RECORD`** (Var_Id: 50)

  - **Descripci√≥n:** Flag indicando si el solicitante tiene alg√∫n registro previo de morosidad crediticia
  - **Valores:** Y, N
  - **Tipo:** Categ√≥rica binaria
  - **Nota:** Variable muy importante para riesgo crediticio

- **`AGE`** (Var_Id: 51)
  - **Descripci√≥n:** Edad del solicitante al momento de la solicitud
  - **Valores:** Valores num√©ricos
  - **Tipo:** Num√©rica continua
  - **Nota:** Variable importante, puede tener outliers (edades muy altas o muy bajas)

#### **Target:**

- **`TARGET_LABEL_BAD=1`** (Var_Id: 54)
  - **Descripci√≥n:** Variable objetivo: BAD=1 (default), GOOD=0 (no default)
  - **Valores:** 0, 1
  - **Tipo:** Num√©rica binaria
  - **Distribuci√≥n:** ~74% NO (0), ~26% YES (1) - **Desbalanceado**

---

## üîß Feature Engineering Implementado

El pipeline crea **17 nuevas features** agrupadas en 7 categor√≠as:

### 1. **Features Financieras Combinadas** (5 features)

```python
# Ingreso total mensual
TOTAL_MONTHLY_INCOME = PERSONAL_MONTHLY_INCOME + OTHER_INCOMES

# Ratio ingreso/activos
INCOME_TO_ASSETS_RATIO = PERSONAL_MONTHLY_INCOME / (PERSONAL_ASSETS_VALUE + 1)

# Ingreso por dependiente
INCOME_PER_DEPENDANT = TOTAL_MONTHLY_INCOME / (QUANT_DEPENDANTS + 1)

# Ratio de otros ingresos sobre ingreso principal
INCOME_RATIO = OTHER_INCOMES / (PERSONAL_MONTHLY_INCOME + 1e-6)

# Activos por dependiente
ASSETS_PER_DEPENDANT = PERSONAL_ASSETS_VALUE / (QUANT_DEPENDANTS + 1)
```

**Nota:** Se usa `+1` o `+1e-6` para evitar divisi√≥n por cero.

### 2. **Features de Estabilidad** (3 features)

```python
# A√±os en residencia (conversi√≥n de meses)
YEARS_IN_RESIDENCE = MONTHS_IN_RESIDENCE / 12

# A√±os en trabajo (conversi√≥n de meses)
YEARS_IN_JOB = MONTHS_IN_THE_JOB / 12

# Score de estabilidad general (promedio normalizado)
STABILITY_SCORE = (MONTHS_IN_RESIDENCE + MONTHS_IN_THE_JOB) / 24
```

**Nota:** `STABILITY_SCORE` usa `.fillna(0)` antes de sumar para manejar missing values.

### 3. **Features de Contacto/Documentaci√≥n** (2 features)

```python
# Total de m√©todos de contacto disponibles
# NOTA: FLAG_MOBILE_PHONE se elimina (constante), solo usamos FLAG_RESIDENCIAL_PHONE y FLAG_EMAIL
CONTACT_METHODS_COUNT = (
    (FLAG_RESIDENCIAL_PHONE == "Y").astype(int).fillna(0) +
    FLAG_EMAIL.fillna(0)
)

# NOTA: DOCUMENTS_COUNT fue removido (usaba columnas constantes: FLAG_HOME_ADDRESS_DOCUMENT, FLAG_RG, FLAG_CPF, FLAG_INCOME_PROOF)
```

### 4. **Features de Tarjetas** (2 features)

```python
# Total de tarjetas (principales + adicionales)
TOTAL_CARDS = (
    FLAG_VISA.fillna(0) +
    FLAG_MASTERCARD.fillna(0) +
    FLAG_DINERS.fillna(0) +
    FLAG_AMERICAN_EXPRESS.fillna(0) +
    FLAG_OTHER_CARDS.fillna(0)
)
# NOTA: QUANT_ADDITIONAL_CARDS se elimina (constante 0), no se usa

# Tiene tarjetas principales (Visa o Mastercard)
HAS_MAJOR_CARDS = (FLAG_VISA.fillna(0) + FLAG_MASTERCARD.fillna(0) > 0).astype(int)
```

### 5. **Features Geogr√°ficas** (3 features)

```python
# Mismo estado residencia y trabajo
SAME_STATE_RES_PROF = (RESIDENCIAL_STATE == PROFESSIONAL_STATE).astype(int)

# Mismo c√≥digo postal residencia y trabajo
SAME_ZIP_RES_PROF = (RESIDENCIAL_ZIP_3 == PROFESSIONAL_ZIP_3).astype(int)

# Naci√≥ en el mismo estado donde reside
BORN_IN_RESIDENCE_STATE = (STATE_OF_BIRTH == RESIDENCIAL_STATE).astype(int)
```

**Nota:** `SAME_CITY_RES_PROF` fue removida porque `PROFESSIONAL_CITY` fue eliminada del dataset (alta cardinalidad + muchos missing).

### 6. **Features de Cuentas Bancarias** (2 features)

```python
# Total de cuentas bancarias
TOTAL_BANKING_ACCOUNTS = (
    QUANT_BANKING_ACCOUNTS.fillna(0) +
    QUANT_SPECIAL_BANKING_ACCOUNTS.fillna(0)
)

# Tiene cuentas bancarias especiales
HAS_SPECIAL_ACCOUNTS = (QUANT_SPECIAL_BANKING_ACCOUNTS > 0).astype(int)
```

### 7. **Features de Edad** (2 features)

```python
# Edad al cuadrado (para capturar relaciones no lineales)
AGE_SQUARED = AGE ** 2

# Grupos de edad (se crea despu√©s de imputar AGE en paso 4)
AGE_GROUP = pd.cut(
    AGE,
    bins=[0, 30, 40, 50, 60, 100],
    labels=["<30", "30-40", "40-50", "50-60", "60+"]
)
# Se convierte a string para encoding
```

**Nota:** `AGE_GROUP` se crea en el **Paso 4** (despu√©s de imputar missing values de AGE), pero se documenta aqu√≠ porque es parte del feature engineering.

### 6. **Features de Missing Values (Indicadores)** (6 features)

Se crean **binarias** (0/1) indicando si la variable original tiene missing:

```python
# Indicadores de missing para variables importantes
MISSING_PROFESSION_CODE
MISSING_MONTHS_IN_RESIDENCE
MISSING_MATE_PROFESSION_CODE
MISSING_MATE_EDUCATION_LEVEL
MISSING_RESIDENCE_TYPE
MISSING_OCCUPATION_TYPE
```

**Nota:** `MISSING_PROFESSIONAL_CITY` y `MISSING_PROFESSIONAL_BOROUGH` fueron removidos porque estas columnas fueron eliminadas en el Paso 1 (alta cardinalidad + muchos missing).

**Total de features creadas:** 17 nuevas features + 6 indicadores de missing = **23 nuevas columnas**

**Nota:** Algunas features propuestas originalmente fueron removidas porque usaban columnas que se eliminan como constantes (DOCUMENTS_COUNT) o columnas que no existen (QUANT_ADDITIONAL_CARDS en TOTAL_CARDS).

---

## üîÑ Pipeline de Preprocessing - Implementaci√≥n Actual

El pipeline se ejecuta en **6 pasos secuenciales**:

### **Paso 1: Limpieza Inicial** (`_step1_initial_cleaning`)

#### **1.1. Remover ID_CLIENT**

```python
if ID_COL in df.columns:
    df = df.drop(columns=[ID_COL])
```

- Se remueve la columna `ID_CLIENT` (identificador √∫nico, no √∫til para modelado)

#### **1.2. Normalizar Columnas Y/N**

**Antes** de detectar columnas constantes, se normalizan estas columnas:

- `FLAG_RESIDENCIAL_PHONE`: Y/y/1‚Üí"Y", N/n/0‚Üí"N", mantener NaN
- `FLAG_MOBILE_PHONE`: Y/y/1‚Üí"Y", N/n/0‚Üí"N", mantener NaN
- `COMPANY`: Y/y/1‚Üí"Y", N/n/0‚Üí"N", mantener NaN
- `FLAG_PROFESSIONAL_PHONE`: Y/y/1‚Üí"Y", N/n/0‚Üí"N", mantener NaN
- `FLAG_ACSP_RECORD`: Y/y/1‚Üí"Y", N/n/0‚Üí"N", mantener NaN

```python
df[col] = df[col].replace({"Y": "Y", "y": "Y", "N": "N", "n": "N", 1: "Y", 0: "N"})
df[col] = df[col].astype(object)  # Mantener como object para preservar NaN
```

**Raz√≥n:** Se normalizan a "Y"/"N" pero se mantienen como strings para preservar NaN como categor√≠a distinta en el encoding posterior (Paso 5). Esto permite que el modelo aprenda de la ausencia de informaci√≥n.

#### **1.3. Identificar y Remover Columnas Constantes y Alta Cardinalidad + Muchos Missing**

**Solo en entrenamiento** (cuando `self.is_fitted == False`):

```python
# Detectar constantes:
# - Columnas con nunique(dropna=True) == 0 (todas NaN)
# - Columnas con nunique(dropna=True) == 1 (un solo valor √∫nico)
# - Columnas num√©ricas con std() == 0 (sin varianza)
constant_cols = [col for col in df.columns if ...]
self.constant_columns_removed = constant_cols  # Guardar para aplicar despu√©s

# Remover columnas de alta cardinalidad con muchos missing
high_card_missing_cols = [col for col in HIGH_CARDINALITY_MANY_MISSING_COLS if col in df.columns]
self.high_cardinality_many_missing_removed = high_card_missing_cols
```

**Resultado t√≠pico:** Se remueven:

- **9 columnas constantes** identificadas en el EDA:
  - `CLERK_TYPE` (todos "C")
  - `QUANT_ADDITIONAL_CARDS` (todos 1)
  - `EDUCATION_LEVEL` (todos 1)
  - `FLAG_MOBILE_PHONE` (todos "N")
  - `FLAG_HOME_ADDRESS_DOCUMENT` (todos 0)
  - `FLAG_RG` (todos 0)
  - `FLAG_CPF` (todos 0)
  - `FLAG_INCOME_PROOF` (todos 0)
  - `FLAG_ACSP_RECORD` (todos "N")
- **2 columnas de alta cardinalidad + muchos missing:**
  - `PROFESSIONAL_CITY` (2,236 categor√≠as, 67.6% missing)
  - `PROFESSIONAL_BOROUGH` (5,057 categor√≠as, 67.6% missing)

**En producci√≥n:** Se usa la lista guardada `self.constant_columns_removed` y `self.high_cardinality_many_missing_removed` para remover las mismas columnas.

**Resultado:** De 53 columnas ‚Üí **42 columnas** (despu√©s de remover 9 constantes + 2 alta cardinalidad + 1 ID)

---

### **Paso 2: Manejo de Outliers** (`_step2_handle_outliers`)

#### **No se aplica Winsorization**

**Decisi√≥n:** Basado en el EDA, el porcentaje de outliers es bajo (~2% m√°ximo) y los valores extremos son **informativos para credit risk**. Por ejemplo, un ingreso muy alto o muy bajo puede ser una se√±al importante para el modelo.

**Proceso:**

```python
# Simplemente retorna una copia del DataFrame sin modificar
return df.copy()
```

**Raz√≥n:** Los outliers en variables financieras (ingresos, activos) y demogr√°ficas (edad) pueden contener informaci√≥n valiosa sobre el perfil de riesgo del solicitante. El modelo puede aprender de estos valores extremos.

---

### **Paso 3: Feature Engineering** (`_step3_feature_engineering`)

#### **Crear 19 nuevas features** (descritas arriba en secci√≥n "Feature Engineering Implementado")

**Orden de creaci√≥n:**

1. Features financieras (5)
2. Features de estabilidad (3)
3. Features de contacto/documentaci√≥n (2)
4. Features de tarjetas (2)
5. Features geogr√°ficas (4)
6. Features de cuentas bancarias (2)
7. Features de edad (1: AGE_SQUARED; AGE_GROUP se crea en Paso 4)

**Resultado:** De 42 columnas ‚Üí **59 columnas** (42 originales + 17 nuevas)

**Nota:** Los indicadores de missing (6) se crean en el Paso 4, no aqu√≠.

---

### **Paso 4: Manejo de Missing Values** (`_step4_missing_values`)

#### **4.1. Crear Indicadores de Missing**

**Antes** de imputar, se crean 6 indicadores binarios (0/1):

```python
for col in MISSING_INDICATOR_COLS:
    indicator_col = f"MISSING_{col}"
    df[indicator_col] = df[col].isna().astype(int)
```

**Variables con indicadores:**

- `MISSING_PROFESSION_CODE`
- `MISSING_MONTHS_IN_RESIDENCE`
- `MISSING_MATE_PROFESSION_CODE`
- `MISSING_MATE_EDUCATION_LEVEL`
- `MISSING_RESIDENCE_TYPE`
- `MISSING_OCCUPATION_TYPE`

**Nota:** `MISSING_PROFESSIONAL_CITY` y `MISSING_PROFESSIONAL_BOROUGH` no se crean porque estas columnas fueron removidas en el Paso 1.

**Resultado:** De 59 columnas ‚Üí **65 columnas** (59 + 6 indicadores)

#### **4.2. Separar Columnas Categ√≥ricas y Num√©ricas**

**Solo en entrenamiento:**

```python
self.categorical_columns = df.select_dtypes(include=["object", "category"]).columns.tolist()
self.numeric_columns = df.select_dtypes(include=["number"]).columns.tolist()
```

#### **4.3. Imputar Categ√≥ricas con Moda**

**Exclusiones importantes:**

Las siguientes columnas se **excluyen** de la imputaci√≥n categ√≥rica para preservar NaN como categor√≠a distinta en encoding:

- **Columnas Y/N:** `FLAG_RESIDENCIAL_PHONE`, `FLAG_MOBILE_PHONE`, `COMPANY`, `FLAG_PROFESSIONAL_PHONE`, `FLAG_ACSP_RECORD`
- **Columnas binarias:** Cualquier columna con exactamente 2 valores √∫nicos (excluyendo Y/N)
- **Columnas de alta cardinalidad (>100 categor√≠as):** `CITY_OF_BIRTH`, `RESIDENCIAL_CITY`, `RESIDENCIAL_BOROUGH`, `RESIDENCIAL_ZIP_3`, `PROFESSIONAL_ZIP_3`, `RESIDENCIAL_PHONE_AREA_CODE`, `PROFESSIONAL_PHONE_AREA_CODE`

**Proceso:**

```python
# Identificar columnas a excluir
cols_to_exclude = yn_cols + binary_cols + high_cardinality_cols
self.categorical_columns = [col for col in all_categorical_columns if col not in cols_to_exclude]

# Imputar solo las columnas categ√≥ricas restantes
self.categorical_imputer = SimpleImputer(strategy="most_frequent")
df[self.categorical_columns] = self.categorical_imputer.transform(df[self.categorical_columns])
```

**Estrategia:** `most_frequent` (moda) - valor m√°s com√∫n para cada columna.

**Raz√≥n de exclusi√≥n:** Preservar NaN permite que el modelo aprenda de la ausencia de informaci√≥n. En Frequency Encoding, los NaN se convierten en "MISSING" con frecuencia baja, lo cual es informativo.

#### **4.4. Imputar Num√©ricas con Mediana**

```python
self.numeric_imputer = SimpleImputer(strategy="median")
# Se ajusta solo con datos de entrenamiento
df[self.numeric_columns] = self.numeric_imputer.transform(df[self.numeric_columns])
```

**Estrategia:** `median` (mediana) - valor central para cada columna num√©rica.

#### **4.5. Crear AGE_GROUP**

**Despu√©s** de imputar AGE:

```python
df["AGE_GROUP"] = pd.cut(
    df["AGE"],
    bins=[0, 30, 40, 50, 60, 100],
    labels=["<30", "30-40", "40-50", "50-60", "60+"]
)
df["AGE_GROUP"] = df["AGE_GROUP"].astype(str)  # Convertir a string para encoding
```

**Resultado:** De 65 columnas ‚Üí **66 columnas** (65 + 1 AGE_GROUP)

---

### **Paso 5: Encoding** (`_step5_encoding`)

#### **5.1. Identificar Tipos de Columnas Categ√≥ricas**

**Solo en entrenamiento**, se clasifican las categ√≥ricas:

```python
# Y/N: columnas especiales que preservan NaN
yn_cols_in_data = [col for col in YN_COLUMNS if col in df.columns]

# Binarias: exactamente 2 valores √∫nicos (excluyendo Y/N)
self.binary_cat_columns = [col for col in cat_cols
                          if col not in yn_cols_in_data
                          and df[col].nunique(dropna=True) == 2]

# M√∫ltiples categor√≠as: separar por cardinalidad
multi_cat_columns = [col for col in cat_cols
                     if col not in self.binary_cat_columns
                     and col not in yn_cols_in_data]

# Baja cardinalidad: ‚â§20 categor√≠as (umbral configurable, default=20)
low_card_cols = [col for col in multi_cat_columns
                if df[col].nunique(dropna=True) <= self.low_cardinality_threshold]

# Media cardinalidad: 21-100 categor√≠as (agrupar poco frecuentes + OneHot)
medium_card_cols = [col for col in multi_cat_columns
                   if self.low_cardinality_threshold < df[col].nunique(dropna=True) <= GROUPING_THRESHOLD]

# Alta cardinalidad: >100 categor√≠as (Frequency Encoding)
high_card_cols = [col for col in multi_cat_columns
                 if df[col].nunique(dropna=True) > GROUPING_THRESHOLD]

self.ohe_cat_columns = low_card_cols + medium_card_cols  # Ambas usan OneHot
self.frequency_encoding_columns = high_card_cols
```

#### **5.2. Encoding de Binarias: OrdinalEncoder (preserva NaN)**

```python
# Convertir NaN a "MISSING" para preservarlo como categor√≠a
binary_df = df[binary_cols].copy().fillna("MISSING")

self.binary_encoder = OrdinalEncoder(
    handle_unknown="use_encoded_value",
    unknown_value=-1
)
encoded_binary = self.binary_encoder.transform(binary_df)
```

**Resultado:** Binarias se convierten a n√∫meros (0, 1, 2) donde 2 representa "MISSING" (1 columna ‚Üí 1 columna)

**Ejemplos:** `SEX` (M/F) ‚Üí 0/1, `APPLICATION_SUBMISSION_TYPE` (Web/Carga) ‚Üí 0/1

#### **5.3. Encoding de Y/N: OrdinalEncoder (preserva NaN)**

```python
# Convertir NaN a "MISSING" para preservarlo como categor√≠a
yn_df = df[yn_cols_in_data].copy().fillna("MISSING")

self.yn_encoder = OrdinalEncoder(
    handle_unknown="use_encoded_value",
    unknown_value=-1
)
encoded_yn = self.yn_encoder.transform(yn_df)
```

**Resultado:** Y/N se convierten a n√∫meros (Y=0, N=1, MISSING=2) (1 columna ‚Üí 1 columna)

**Raz√≥n:** Preservar NaN como "MISSING" permite que el modelo aprenda de la ausencia de informaci√≥n.

#### **5.4. Agrupaci√≥n de Categor√≠as Poco Frecuentes (Media Cardinalidad)**

**Antes de aplicar OneHot**, se agrupan categor√≠as con <10 ocurrencias en "OTROS":

```python
# Solo en entrenamiento
for col in medium_card_cols:
    value_counts = df[col].value_counts()
    rare_categories = value_counts[value_counts < MIN_FREQUENCY_FOR_GROUPING].index.tolist()
    if rare_categories:
        self.rare_categories_map[col] = rare_categories  # Guardar para transformaci√≥n
        df[col] = df[col].replace(rare_categories, "OTROS")
```

**Resultado:** Reduce la cardinalidad efectiva antes de OneHot, evitando crear demasiadas columnas.

**Ejemplo:** Si `PROFESSIONAL_PHONE_AREA_CODE` tiene 87 categor√≠as pero 20 tienen <10 ocurrencias, se agrupan en "OTROS", quedando 68 categor√≠as √∫nicas.

#### **5.5. Encoding de Baja y Media Cardinalidad: OneHotEncoder**

```python
self.ohe_encoder = OneHotEncoder(
    handle_unknown="ignore",  # Si aparece categor√≠a nueva, se ignora (todas las columnas = 0)
    sparse_output=False
)
ohe_array = self.ohe_encoder.transform(df[ohe_cols])
ohe_df = pd.DataFrame(ohe_array, columns=self.ohe_encoder.get_feature_names_out(ohe_cols))
df = df.drop(columns=ohe_cols)  # Remover columnas originales
df = pd.concat([df, ohe_df], axis=1)  # Agregar columnas one-hot
```

**Resultado:** 1 columna categ√≥rica ‚Üí **N columnas binarias** (una por categor√≠a)

**Ejemplos:**

- `SEX` (M, F) ‚Üí `SEX_M` (0/1), `SEX_F` (0/1) = **2 columnas**
- `RESIDENCE_TYPE` (1, 2, 3, 4, 5) ‚Üí `RESIDENCE_TYPE_1`, `RESIDENCE_TYPE_2`, ..., `RESIDENCE_TYPE_5` = **5 columnas**
- `PROFESSIONAL_PHONE_AREA_CODE` (despu√©s de agrupar) ‚Üí ~68 columnas

#### **5.6. Encoding de Alta Cardinalidad: Frequency Encoding**

**Estrategia:** Codificar por frecuencia relativa (proporci√≥n de aparici√≥n) en lugar de orden arbitrario.

```python
# En entrenamiento: calcular frecuencias relativas
for col in high_card_cols:
    value_counts = df[col].value_counts()
    total = len(df[col].dropna())
    freq_map = (value_counts / total).to_dict()  # Categor√≠a ‚Üí frecuencia (0-1)

    # Para NaN, usar frecuencia promedio de categor√≠as raras
    if pd.isna(df[col]).any():
        rare_freq = value_counts[value_counts < MIN_FREQUENCY_FOR_GROUPING].sum() / total
        freq_map["MISSING"] = rare_freq if rare_freq > 0 else 0.001

    self.frequency_encoders[col] = freq_map

# Aplicar encoding
df[col] = df[col].fillna("MISSING").map(self.frequency_encoders[col])
# Si hay categor√≠as nuevas (unknown), usar frecuencia m√≠nima
if df[col].isna().any():
    min_freq = min(self.frequency_encoders[col].values())
    df[col] = df[col].fillna(min_freq)
df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.001)
```

**Resultado:** Alta cardinalidad se convierte a valores num√©ricos continuos (0-1) basados en frecuencia (1 columna ‚Üí 1 columna)

**Ventajas:**

- **No introduce orden artificial** (a diferencia de OrdinalEncoder)
- **Captura la frecuencia** de cada categor√≠a (m√°s frecuente = valor m√°s alto)
- **Maneja NaN** como "MISSING" con frecuencia baja
- **Maneja categor√≠as nuevas** usando frecuencia m√≠nima

**Ejemplos:**

- `CITY_OF_BIRTH` (9,910 categor√≠as) ‚Üí valores 0.0001-0.05 seg√∫n frecuencia
- `RESIDENCIAL_BOROUGH` (14,511 categor√≠as) ‚Üí valores 0.0001-0.03 seg√∫n frecuencia
- `RESIDENCIAL_CITY` (3,529 categor√≠as) ‚Üí valores 0.0001-0.08 seg√∫n frecuencia

**Resultado final:** Aproximadamente **~117 features** (var√≠a seg√∫n categor√≠as √∫nicas en cada columna)

---

### **Paso 6: Escalado** (`_step6_scaling`)

#### **MinMaxScaler para Todas las Columnas Num√©ricas**

```python
self.scaler = MinMaxScaler()
numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
# Remover TARGET_COL si existe
df[numeric_cols] = self.scaler.transform(df[numeric_cols])
```

**Resultado:**

- Todas las features num√©ricas se normalizan al rango **[0, 1]**
- F√≥rmula: `(x - min) / (max - min)`
- Se guardan `min_` y `max_` de cada columna para aplicar en producci√≥n

**NO cambia el n√∫mero de columnas**, solo normaliza los valores.

**Resultado final:** **~117 features normalizadas** (todas en rango 0-1)

---

## üìä Resumen de Transformaciones

### **Transformaci√≥n de Columnas:**

```
53 columnas originales
    ‚Üì Paso 1: Limpieza
    - Remueve ID_CLIENT (1 columna)
    - Remueve 9 columnas constantes
    - Remueve 2 columnas alta cardinalidad + muchos missing
    = 42 columnas
    ‚Üì Paso 2: Outliers
    - No se aplica Winsorization (outliers son informativos)
    = 42 columnas
    ‚Üì Paso 3: Feature Engineering
    - Crea 17 nuevas features
    = 59 columnas
    ‚Üì Paso 4: Missing Values
    - Crea 6 indicadores de missing
    - Crea AGE_GROUP (1 columna)
    = 66 columnas
    ‚Üì Paso 5: Encoding
    - OneHotEncoder expande columnas (1 ‚Üí m√∫ltiples) para baja/media cardinalidad
    - Frequency Encoding mantiene (1 ‚Üí 1) para alta cardinalidad
    - OrdinalEncoder mantiene (1 ‚Üí 1) para binarias y Y/N
    = ~117 features
    ‚Üì Paso 6: Scaling
    - MinMaxScaler normaliza (no cambia n√∫mero)
    = ~117 features finales (todas normalizadas 0-1)
```

---

## üíæ Guardado del Pipeline

### **Archivo:** `preprocessor.joblib`

**Contiene:**

- `PreprocessingPipeline` completo con:
  - `constant_columns_removed`: Lista de 9 columnas constantes
  - `outlier_limits`: Diccionario con l√≠mites (lower/upper) de 10 variables
  - `categorical_columns`: Lista de columnas categ√≥ricas identificadas
  - `numeric_columns`: Lista de columnas num√©ricas identificadas
  - `binary_cat_columns`: Lista de binarias
  - `ohe_cat_columns`: Lista de baja cardinalidad (OneHot)
  - `ordinal_cat_columns`: Lista de alta cardinalidad (Ordinal)
  - `feature_engineering_features`: Lista de 19 features creadas
  - `categorical_imputer`: SimpleImputer con modas aprendidas
  - `numeric_imputer`: SimpleImputer con medianas aprendidas
  - `binary_encoder`: OrdinalEncoder para binarias
  - `ohe_encoder`: OneHotEncoder para baja cardinalidad
  - `ordinal_encoder`: OrdinalEncoder para alta cardinalidad
  - `scaler`: MinMaxScaler con min/max aprendidos
  - `is_fitted`: Flag indicando que el pipeline est√° entrenado

**Tama√±o t√≠pico:** ~1-2 MB

---

## üîÑ Uso en Producci√≥n

### **Entrenamiento:**

```python
pipeline = PreprocessingPipeline(low_cardinality_threshold=20)
X_train_processed = pipeline.fit_transform(X_train, X_val, X_test)
pipeline.save()  # Guarda preprocessor.joblib
```

### **Producci√≥n (nuevos datos):**

```python
pipeline = PreprocessingPipeline.load()  # Carga preprocessor.joblib
X_new_processed = pipeline.transform(X_new)  # Aplica transformaciones guardadas
```

**Garant√≠as:**

- Mismas columnas constantes removidas
- Mismos l√≠mites de outliers aplicados
- Mismas modas/medianas para imputaci√≥n
- Mismas categor√≠as aprendidas para encoding
- Mismos min/max para escalado

---

## ‚ö†Ô∏è Consideraciones Importantes

1. **Desbalanceo de target:** 74% NO vs 26% YES

   - Considerar t√©cnicas de balanceo (SMOTE, undersampling, class_weight)
   - Usar m√©tricas apropiadas (ROC-AUC, Precision-Recall, F1-score)

2. **Missing Values:**

   - Variables con muchos missing:
     - `PROFESSIONAL_CITY`, `PROFESSIONAL_BOROUGH` - Muchos missing
     - `MATE_PROFESSION_CODE`, `MATE_EDUCATION_LEVEL` - Muchos missing
   - Usar indicadores de missing como features
   - Considerar que missing puede ser informativo (ej: no tiene trabajo formal)

3. **Variables de Alta Cardinalidad:**

   - `RESIDENCIAL_CITY` - Muchas categor√≠as
   - `RESIDENCIAL_BOROUGH` - Muchas categor√≠as
   - `PROFESSIONAL_CITY` - Muchas categor√≠as + muchos missing
   - `CITY_OF_BIRTH` - Muchas categor√≠as
   - **Estrategia:** Agrupar categor√≠as poco frecuentes o usar Target Encoding

4. **Variables Geogr√°ficas:**

   - Pueden tener informaci√≥n √∫til sobre riesgo por regi√≥n
   - Considerar codificar estados/ciudades por riesgo promedio (Target Encoding)
   - `RESIDENCIAL_ZIP_3` y `PROFESSIONAL_ZIP_3` pueden ser √∫tiles para agrupar

5. **Outliers:**

   - Variables financieras (`PERSONAL_MONTHLY_INCOME`, `PERSONAL_ASSETS_VALUE`) pueden tener valores extremos
   - `AGE` puede tener valores an√≥malos
   - **Estrategia:** Capping con IQR o Winsorization

6. **Variables Constantes:**

   - Verificar si hay columnas con todos los valores iguales
   - Remover antes del encoding para evitar problemas

7. **Variables con Encoding Desconocido:**
   - `MARITAL_STATUS`, `EDUCATION_LEVEL`, `RESIDENCE_TYPE`, `OCCUPATION_TYPE` tienen encoding no informado
   - Tratar como categ√≥ricas ordinales si tienen orden l√≥gico, sino como categ√≥ricas nominales

---

---

## ‚öôÔ∏è Configuraci√≥n

### **Par√°metros del Pipeline:**

```python
PreprocessingPipeline(low_cardinality_threshold=20)
```

- `low_cardinality_threshold`: Umbral para separar baja vs alta cardinalidad (default: 20)
  - ‚â§20 categor√≠as ‚Üí OneHotEncoder
  - > 20 categor√≠as ‚Üí OrdinalEncoder

### **Constantes Configuradas:**

```python
# Columnas Y/N a convertir
YN_COLUMNS = [
    "FLAG_RESIDENCIAL_PHONE",
    "FLAG_MOBILE_PHONE",
    "COMPANY",
    "FLAG_PROFESSIONAL_PHONE",
    "FLAG_ACSP_RECORD",
]

# Variables para indicadores de missing
MISSING_INDICATOR_COLS = [
    "PROFESSIONAL_CITY",
    "PROFESSIONAL_BOROUGH",
    "PROFESSION_CODE",
    "MONTHS_IN_RESIDENCE",
    "MATE_PROFESSION_CODE",
    "MATE_EDUCATION_LEVEL",
    "RESIDENCE_TYPE",
    "OCCUPATION_TYPE",
]

# Umbrales para estrategias de encoding seg√∫n cardinalidad
GROUPING_THRESHOLD = 100  # Columnas con >100 categor√≠as: Frequency Encoding
MIN_FREQUENCY_FOR_GROUPING = 10  # Categor√≠as con <10 ocurrencias se agrupan en "OTROS"
```

---

## ‚ö†Ô∏è Consideraciones Importantes

1. **Orden de Pasos es Cr√≠tico:**

   - Feature engineering debe ir **antes** de encoding
   - Missing indicators deben crearse **antes** de imputar
   - Encoding debe ir **despu√©s** de imputar (para tener valores completos)

2. **Manejo de Valores Desconocidos:**

   - OneHotEncoder: `handle_unknown="ignore"` ‚Üí categor√≠as nuevas = todas columnas en 0
   - OrdinalEncoder: `unknown_value=-1` ‚Üí categor√≠as nuevas = -1

3. **Frequency Encoding para Alta Cardinalidad:**

   - Columnas con >100 categor√≠as usan Frequency Encoding (frecuencia relativa)
   - No introduce orden artificial como OrdinalEncoder
   - NaN se preservan y se codifican como "MISSING" con frecuencia baja
   - Categor√≠as nuevas (unknown) usan frecuencia m√≠nima

4. **Missing Values Informativos:**

   - Los indicadores de missing capturan informaci√≥n √∫til (ej: missing en variables profesionales puede indicar desempleo)
   - Los missing se imputan pero tambi√©n se crean indicadores

5. **Escalado Final:**
   - Todas las features se normalizan a [0, 1]
   - Esto ayuda a modelos que usan distancias (KNN) o regularizaci√≥n
   - No cambia relaciones entre features, solo escala

---

## üìö Referencias

- **Hallazgos del EDA:** Ver `EDA_FINDINGS.md` para detalles completos
- **Columnas constantes:** 9 columnas identificadas y removidas autom√°ticamente
- **Columnas removidas:** 2 columnas de alta cardinalidad + muchos missing (PROFESSIONAL_CITY, PROFESSIONAL_BOROUGH)
- **Outliers:** No se aplica Winsorization (outliers son informativos)
- **Feature Engineering:** 17 features implementadas seg√∫n hallazgos del EDA
- **Encoding:** Frequency Encoding para alta cardinalidad (>100), agrupaci√≥n + OneHot para media cardinalidad (21-100)

---

**Estado:** ‚úÖ Implementado y funcionando. Pipeline guardado en `models/preprocessor/preprocessor.joblib`.
