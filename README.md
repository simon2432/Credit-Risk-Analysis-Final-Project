# Credit Risk Analysis - Final Project

## ğŸ“‹ Project Description

This project aims to develop a complete credit risk analysis system using Machine Learning techniques. The system will evaluate the probability of customer default and make informed decisions about credit approval or rejection.

**Dataset**: PAKDD2010 - Credit Risk Analysis Dataset

## ğŸ¯ Objectives

1. **EDA (Exploratory Data Analysis)**: Perform a complete exploratory analysis of the customer and credit dataset.
2. **Preprocessing Pipeline**: Design a standard preprocessing pipeline for the entire team.
3. **Model Training**: Train and compare various ML models for credit risk (logistic regression, decision trees, ensembles, etc.).
4. **Model Selection**: Choose a final model based on evaluation metrics.
5. **API Deployment**: Expose the model through a REST API using FastAPI.
6. **UI Demo**: Build a simple interface (Streamlit) to demonstrate how a "bank" would use the model to approve/reject credits.

## ğŸ“ Project Structure

```
Credit-Risk-Analysis-Final-Project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Original PAKDD2010 dataset unprocessed
â”‚   â”‚   â”œâ”€â”€ PAKDD2010_Modeling_Data.txt
â”‚   â”‚   â”œâ”€â”€ PAKDD2010_Prediction_Data.txt
â”‚   â”‚   â”œâ”€â”€ PAKDD2010_VariablesList.XLS
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ processed/        # Clean and preprocessed dataset (to be created)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA/              # Exploratory data analysis notebooks
â”‚       â”œâ”€â”€ maria_EDA.ipynb
â”‚       â””â”€â”€ simon_EDA_ordered.ipynb
â”œâ”€â”€ src/                  # Python source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py  # Preprocessing pipeline
â”‚   â”œâ”€â”€ train_model.py    # Model training script
â”‚   â”œâ”€â”€ data_utils.py     # Data loading utilities
â”‚   â”œâ”€â”€ models_config.py  # Model configurations
â”‚   â”œâ”€â”€ config.py         # Configuration paths
â”‚   â”œâ”€â”€ api/              # FastAPI service
â”‚   â”‚   â”œâ”€â”€ server.py
â”‚   â”‚   â””â”€â”€ feature_mapper.py
â”‚   â””â”€â”€ ui/               # Streamlit UI
â”‚       â”œâ”€â”€ simple_app.py
â”‚       â””â”€â”€ ui_options.json
â”œâ”€â”€ models/               # Saved trained models (gitignored, except .gitkeep)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Original dataset (gitignored, except .gitkeep)
â”‚   â””â”€â”€ processed/        # Processed data (gitignored, except .gitkeep)
â”œâ”€â”€ Dockerfile            # Docker for API + model
â”œâ”€â”€ docker-compose.yml    # Service orchestration
â”œâ”€â”€ requirements.txt      # Project dependencies
â””â”€â”€ README.md             # This file
```

## ğŸš€ Installation and Setup

### 1. Create virtual environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python -m venv venv
source venv/bin/activate
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Verify installation

```bash
python -c "import pandas, sklearn, fastapi; print('Dependencies installed correctly')"
```

## ğŸ“ Current Project Status

The project is **fully functional** and ready for use:

- âœ… **Folder structure**: Complete project organization
- âœ… **Dataset**: PAKDD2010 data processing implemented
- âœ… **EDA**: Exploratory analysis completed (`notebooks/EDA/`)
- âœ… **Preprocessing**: Complete preprocessing pipeline implemented (`src/preprocessing.py`)
- âœ… **Models**: Training and comparison implemented (`src/train_model.py`)
  - Logistic Regression, Random Forest, Gradient Boosting
  - Automatic model selection based on ROC-AUC
  - Optimal threshold calculation
- âœ… **API**: FastAPI service implemented (`src/api/server.py`)
  - `/predict` endpoint for credit risk evaluation
  - Automatic model and preprocessor loading
- âœ… **UI**: Streamlit interface implemented (`src/ui/simple_app.py`)
  - User-friendly form for credit evaluation
  - Real-time predictions via API

## ğŸ“ Quick Start

For detailed instructions, see:

- **`SISTEMA_COMPLETO.md`**: Complete system documentation with quick start guide
- **`DOCKER_QUICK.md`**: Docker setup and usage guide
- **`MODELOS_PERSONALIZADOS.md`**: Guide to add custom models
- **`PREPROCESSING_PLAN.md`**: Detailed preprocessing documentation

**Quick setup:**

1. Place dataset files in `data/raw/`
2. Run `docker-compose up --build`
3. Train models: `python -m src.train_model`
4. Use UI: http://localhost:8501

## ğŸ‘¥ Team

This project is being developed by a team of 6 people.
